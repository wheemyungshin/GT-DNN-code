{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'keras'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-0d60ca539208>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'keras'"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "import keras\n",
    "import keras.preprocessing.image\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "\n",
    "# Allow relative imports when being executed as script.\n",
    "if __name__ == \"__main__\" and __package__ is None:\n",
    "    sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..', '..'))\n",
    "    import keras_retinanet.bin  # noqa: F401\n",
    "    __package__ = \"keras_retinanet.bin\"\n",
    "\n",
    "# Change these to absolute imports if you copy this script outside the keras_retinanet package.\n",
    "from .. import layers  # noqa: F401\n",
    "from .. import losses\n",
    "from .. import models\n",
    "from ..callbacks import RedirectModel\n",
    "from ..callbacks.eval import Evaluate\n",
    "from ..models.retinanet import retinanet_bbox\n",
    "from ..preprocessing.csv_generator import CSVGenerator\n",
    "from ..preprocessing.kitti import KittiGenerator\n",
    "from ..preprocessing.open_images import OpenImagesGenerator\n",
    "from ..preprocessing.pascal_voc import PascalVocGenerator\n",
    "from ..utils.anchors import make_shapes_callback\n",
    "from ..utils.config import read_config_file, parse_anchor_parameters\n",
    "from ..utils.keras_version import check_keras_version\n",
    "from ..utils.model import freeze as freeze_model\n",
    "from ..utils.transform import random_transform_generator\n",
    "from ..utils.image import random_visual_effect_generator\n",
    "\n",
    "from ..utils.visualization import draw_detections, draw_annotations\n",
    "\n",
    "def get_session():\n",
    "    \"\"\" Construct a modified tf session.\n",
    "    \"\"\"\n",
    "    config = tf.ConfigProto()\n",
    "    config.gpu_options.allow_growth = True\n",
    "    return tf.Session(config=config)\n",
    "\n",
    "\n",
    "def main(args=None):\n",
    "    # parse arguments\n",
    "    if args is None:\n",
    "        args = sys.argv[1:]\n",
    "    args = parse_args(args)\n",
    "\n",
    "    # create object that stores backbone information\n",
    "    backbone = models.backbone(args.backbone)\n",
    "\n",
    "    # make sure keras is the minimum required version\n",
    "    check_keras_version()\n",
    "\n",
    "    # optionally choose specific GPU\n",
    "    if args.gpu:\n",
    "        os.environ['CUDA_VISIBLE_DEVICES'] = args.gpu\n",
    "    keras.backend.tensorflow_backend.set_session(get_session())\n",
    "\n",
    "    # create the generators\n",
    "    train_generator, validation_generator = create_generators(args, backbone.preprocess_image)\n",
    "    \n",
    "    \n",
    "    for i in range(train_generator.size()):\n",
    "        print(i)\n",
    "        transformed_images, transformed_annotations = train_generator.random_transformed_images(i)\n",
    "        transformed_image = transformed_images[0]\n",
    "        transformed_annotation = transformed_annotations[0]\n",
    "        draw_annotations(transformed_image, transformed_annotation, label_to_name=train_generator.label_to_name)\n",
    "        cv2.imwrite(os.path.join('test-image', '{}.png'.format(i)), transformed_image)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_args(parsed_args):\n",
    "    \"\"\" Function to check for inherent contradictions within parsed arguments.\n",
    "    For example, batch_size < num_gpus\n",
    "    Intended to raise errors prior to backend initialisation.\n",
    "\n",
    "    Args\n",
    "        parsed_args: parser.parse_args()\n",
    "\n",
    "    Returns\n",
    "        parsed_args\n",
    "    \"\"\"\n",
    "\n",
    "    if parsed_args.multi_gpu > 1 and parsed_args.batch_size < parsed_args.multi_gpu:\n",
    "        raise ValueError(\n",
    "            \"Batch size ({}) must be equal to or higher than the number of GPUs ({})\".format(parsed_args.batch_size,\n",
    "                                                                                             parsed_args.multi_gpu))\n",
    "\n",
    "    if parsed_args.multi_gpu > 1 and parsed_args.snapshot:\n",
    "        raise ValueError(\n",
    "            \"Multi GPU training ({}) and resuming from snapshots ({}) is not supported.\".format(parsed_args.multi_gpu,\n",
    "                                                                                                parsed_args.snapshot))\n",
    "\n",
    "    if parsed_args.multi_gpu > 1 and not parsed_args.multi_gpu_force:\n",
    "        raise ValueError(\"Multi-GPU support is experimental, use at own risk! Run with --multi-gpu-force if you wish to continue.\")\n",
    "\n",
    "    if 'resnet' not in parsed_args.backbone:\n",
    "        warnings.warn('Using experimental backbone {}. Only resnet50 has been properly tested.'.format(parsed_args.backbone))\n",
    "\n",
    "    return parsed_args\n",
    "\n",
    "def parse_args(args):\n",
    "    \"\"\" Parse the arguments.\n",
    "    \"\"\"\n",
    "    parser     = argparse.ArgumentParser(description='Simple training script for training a RetinaNet network.')\n",
    "    subparsers = parser.add_subparsers(help='Arguments for specific dataset types.', dest='dataset_type')\n",
    "    subparsers.required = True\n",
    "\n",
    "    coco_parser = subparsers.add_parser('coco')\n",
    "    coco_parser.add_argument('coco_path', help='Path to dataset directory (ie. /tmp/COCO).')\n",
    "\n",
    "    pascal_parser = subparsers.add_parser('pascal')\n",
    "    pascal_parser.add_argument('pascal_path', help='Path to dataset directory (ie. /tmp/VOCdevkit).')\n",
    "\n",
    "    kitti_parser = subparsers.add_parser('kitti')\n",
    "    kitti_parser.add_argument('kitti_path', help='Path to dataset directory (ie. /tmp/kitti).')\n",
    "\n",
    "    def csv_list(string):\n",
    "        return string.split(',')\n",
    "\n",
    "    oid_parser = subparsers.add_parser('oid')\n",
    "    oid_parser.add_argument('main_dir', help='Path to dataset directory.')\n",
    "    oid_parser.add_argument('--version',  help='The current dataset version is v4.', default='v4')\n",
    "    oid_parser.add_argument('--labels-filter',  help='A list of labels to filter.', type=csv_list, default=None)\n",
    "    oid_parser.add_argument('--annotation-cache-dir', help='Path to store annotation cache.', default='.')\n",
    "    oid_parser.add_argument('--parent-label', help='Use the hierarchy children of this label.', default=None)\n",
    "\n",
    "    csv_parser = subparsers.add_parser('csv')\n",
    "    csv_parser.add_argument('annotations', help='Path to CSV file containing annotations for training.')\n",
    "    csv_parser.add_argument('classes', help='Path to a CSV file containing class label mapping.')\n",
    "    csv_parser.add_argument('--val-annotations', help='Path to CSV file containing annotations for validation (optional).')\n",
    "\n",
    "    group = parser.add_mutually_exclusive_group()\n",
    "\n",
    "    parser.add_argument('--backbone',         help='Backbone model used by retinanet.', default='resnet50', type=str)\n",
    "    parser.add_argument('--batch-size',       help='Size of the batches.', default=1, type=int)\n",
    "    parser.add_argument('--gpu',              help='Id of the GPU to use (as reported by nvidia-smi).')\n",
    "    parser.add_argument('--multi-gpu',        help='Number of GPUs to use for parallel processing.', type=int, default=0)\n",
    "    parser.add_argument('--multi-gpu-force',  help='Extra flag needed to enable (experimental) multi-gpu support.', action='store_true')\n",
    "    parser.add_argument('--epochs',           help='Number of epochs to train.', type=int, default=50)\n",
    "    parser.add_argument('--steps',            help='Number of steps per epoch.', type=int, default=10000)\n",
    "    parser.add_argument('--lr',               help='Learning rate.', type=float, default=1e-5)\n",
    "    parser.add_argument('--snapshot-path',    help='Path to store snapshots of models during training (defaults to \\'./snapshots\\')', default='./snapshots')\n",
    "    parser.add_argument('--tensorboard-dir',  help='Log directory for Tensorboard output', default='./logs')\n",
    "    parser.add_argument('--no-snapshots',     help='Disable saving snapshots.', dest='snapshots', action='store_false')\n",
    "    parser.add_argument('--no-evaluation',    help='Disable per epoch evaluation.', dest='evaluation', action='store_false')\n",
    "    parser.add_argument('--freeze-backbone',  help='Freeze training of backbone layers.', action='store_true')\n",
    "    parser.add_argument('--random-transform', help='Randomly transform image and annotations.', action='store_true')\n",
    "    parser.add_argument('--image-min-side',   help='Rescale the image so the smallest side is min_side.', type=int, default=800)\n",
    "    parser.add_argument('--image-max-side',   help='Rescale the image if the largest side is larger than max_side.', type=int, default=1333)\n",
    "    parser.add_argument('--config',           help='Path to a configuration parameters .ini file.')\n",
    "    parser.add_argument('--weighted-average', help='Compute the mAP using the weighted average of precisions among classes.', action='store_true')\n",
    "    parser.add_argument('--compute-val-loss', help='Compute validation loss during training', dest='compute_val_loss', action='store_true')\n",
    "\n",
    "    # Fit generator arguments\n",
    "    parser.add_argument('--multiprocessing',  help='Use multiprocessing in fit_generator.', action='store_true')\n",
    "    parser.add_argument('--workers',          help='Number of generator workers.', type=int, default=1)\n",
    "    parser.add_argument('--max-queue-size',   help='Queue length for multiprocessing workers in fit_generator.', type=int, default=10)\n",
    "\n",
    "    return check_args(parser.parse_args(args))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_generators(args, preprocess_image):\n",
    "    \"\"\" Create generators for training and validation.\n",
    "\n",
    "    Args\n",
    "        args             : parseargs object containing configuration for generators.\n",
    "        preprocess_image : Function that preprocesses an image for the network.\n",
    "    \"\"\"\n",
    "    common_args = {\n",
    "        'batch_size'       : args.batch_size,\n",
    "        'config'           : args.config,\n",
    "        'image_min_side'   : args.image_min_side,\n",
    "        'image_max_side'   : args.image_max_side,\n",
    "        'preprocess_image' : preprocess_image,\n",
    "    }\n",
    "\n",
    "    # create random transform generator for augmenting training data\n",
    "    if args.random_transform:\n",
    "        transform_generator = random_transform_generator(\n",
    "            min_rotation=-0.1,\n",
    "            max_rotation=0.1,\n",
    "            min_translation=(-0.1, -0.1),\n",
    "            max_translation=(0.1, 0.1),\n",
    "            min_shear=-0.1,\n",
    "            max_shear=0.1,\n",
    "            min_scaling=(0.9, 0.9),\n",
    "            max_scaling=(1.1, 1.1),\n",
    "            flip_x_chance=0.5,\n",
    "            flip_y_chance=0.5,\n",
    "        )\n",
    "        visual_effect_generator = random_visual_effect_generator(\n",
    "            contrast_range=(0.9, 1.1),\n",
    "            brightness_range=(-.1, .1),\n",
    "            hue_range=(-0.05, 0.05),\n",
    "            saturation_range=(0.95, 1.05)\n",
    "        )\n",
    "    else:\n",
    "        transform_generator = random_transform_generator(flip_x_chance=0.5)\n",
    "        visual_effect_generator = None\n",
    "\n",
    "    if args.dataset_type == 'coco':\n",
    "        # import here to prevent unnecessary dependency on cocoapi\n",
    "        from ..preprocessing.coco import CocoGenerator\n",
    "\n",
    "        train_generator = CocoGenerator(\n",
    "            args.coco_path,\n",
    "            'train2017',\n",
    "            transform_generator=transform_generator,\n",
    "            visual_effect_generator=visual_effect_generator,\n",
    "            **common_args\n",
    "        )\n",
    "\n",
    "        validation_generator = CocoGenerator(\n",
    "            args.coco_path,\n",
    "            'val2017',\n",
    "            shuffle_groups=False,\n",
    "            **common_args\n",
    "        )\n",
    "    elif args.dataset_type == 'pascal':\n",
    "        train_generator = PascalVocGenerator(\n",
    "            args.pascal_path,\n",
    "            'trainval',\n",
    "            transform_generator=transform_generator,\n",
    "            visual_effect_generator=visual_effect_generator,\n",
    "            **common_args\n",
    "        )\n",
    "\n",
    "        validation_generator = PascalVocGenerator(\n",
    "            args.pascal_path,\n",
    "            'test',\n",
    "            shuffle_groups=False,\n",
    "            **common_args\n",
    "        )\n",
    "    elif args.dataset_type == 'csv':\n",
    "        train_generator = CSVGenerator(\n",
    "            args.annotations,\n",
    "            args.classes,\n",
    "            transform_generator=transform_generator,\n",
    "            visual_effect_generator=visual_effect_generator,\n",
    "            **common_args\n",
    "        )\n",
    "\n",
    "        if args.val_annotations:\n",
    "            validation_generator = CSVGenerator(\n",
    "                args.val_annotations,\n",
    "                args.classes,\n",
    "                shuffle_groups=False,\n",
    "                **common_args\n",
    "            )\n",
    "        else:\n",
    "            validation_generator = None\n",
    "    elif args.dataset_type == 'oid':\n",
    "        train_generator = OpenImagesGenerator(\n",
    "            args.main_dir,\n",
    "            subset='train',\n",
    "            version=args.version,\n",
    "            labels_filter=args.labels_filter,\n",
    "            annotation_cache_dir=args.annotation_cache_dir,\n",
    "            parent_label=args.parent_label,\n",
    "            transform_generator=transform_generator,\n",
    "            visual_effect_generator=visual_effect_generator,\n",
    "            **common_args\n",
    "        )\n",
    "\n",
    "        validation_generator = OpenImagesGenerator(\n",
    "            args.main_dir,\n",
    "            subset='validation',\n",
    "            version=args.version,\n",
    "            labels_filter=args.labels_filter,\n",
    "            annotation_cache_dir=args.annotation_cache_dir,\n",
    "            parent_label=args.parent_label,\n",
    "            shuffle_groups=False,\n",
    "            **common_args\n",
    "        )\n",
    "    elif args.dataset_type == 'kitti':\n",
    "        train_generator = KittiGenerator(\n",
    "            args.kitti_path,\n",
    "            subset='train',\n",
    "            transform_generator=transform_generator,\n",
    "            visual_effect_generator=visual_effect_generator,\n",
    "            **common_args\n",
    "        )\n",
    "\n",
    "        validation_generator = KittiGenerator(\n",
    "            args.kitti_path,\n",
    "            subset='val',\n",
    "            shuffle_groups=False,\n",
    "            **common_args\n",
    "        )\n",
    "    else:\n",
    "        raise ValueError('Invalid data type received: {}'.format(args.dataset_type))\n",
    "\n",
    "    return train_generator, validation_generator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sys' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-263240bbee7e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-1-e1b3a3653dae>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;31m# parse arguments\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0margs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparse_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sys' is not defined"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
